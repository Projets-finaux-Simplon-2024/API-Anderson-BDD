{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION ICI CA TELECHARGE LE MODELE\n",
    "# Charger le tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"OrdalieTech/Solon-embeddings-large-0.1\")\n",
    "\n",
    "# Charger le mod√®le\n",
    "model = AutoModel.from_pretrained(\"OrdalieTech/Solon-embeddings-large-0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.99690074  1.2919712   0.81441706 ...  0.10150217 -0.5481098\n",
      "   1.7338686 ]]\n"
     ]
    }
   ],
   "source": [
    "# TEST\n",
    "def extract_features(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "text = \"Bonjour\"\n",
    "features = extract_features(text)\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/09 20:10:18 INFO mlflow.tracking.fluent: Experiment with name 'Solon-embeddings' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/app/mlartifacts/1', creation_time=1723227018432, experiment_id='1', last_update_time=1723227018432, lifecycle_stage='active', name='Solon-embeddings', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D√©finir l'URI de suivi MLflow pour pointer vers votre instance locale\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")  # Changez ceci pour votre URI MLflow\n",
    "\n",
    "# D√©finir l'exp√©rience\n",
    "mlflow.set_experiment(\"Solon-embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/09 20:10:21 WARNING mlflow.utils.requirements_utils: Found torch version (2.2.2+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/08/09 20:10:32 WARNING mlflow.utils.requirements_utils: Found torch version (2.2.2+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/08/09 20:11:05 WARNING mlflow.models.model: Input example should be provided to infer model signature if the model signature is not provided when logging the model.\n",
      "2024/08/09 20:11:07 WARNING mlflow.utils.requirements_utils: Found torch version (2.2.2+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2024/08/09 20:11:11 WARNING mlflow.utils.requirements_utils: Found torch version (2.2.2+cpu) contains a local version label (+cpu). MLflow logged a pip requirement for this package as 'torch==2.2.2' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "Successfully registered model 'pytorch-solon-embeddings-large-model'.\n",
      "2024/08/09 20:11:11 INFO mlflow.store.model_registry.abstract_store: Waiting up to 10 seconds for model version to finish creation. Model name: pytorch-solon-embeddings-large-model, version 1\n",
      "Created version '1' of model 'pytorch-solon-embeddings-large-model'.\n",
      "2024/08/09 20:11:11 INFO mlflow.tracking._tracking_service.client: üèÉ View run rare-doe-302 at: http://localhost:5000/#/experiments/1/runs/6d780e028b664e8cadb6555fcd642692.\n",
      "2024/08/09 20:11:11 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://localhost:5000/#/experiments/1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Exemple de question et de r√©ponses\n",
    "question = [\"Il fait beau\"]\n",
    "responses = [\"Il fait beau\", \"Il est beau\", \"Il va faire beau\", \"Il a fait beau\", \"C'est tr√®s beau\"]\n",
    "response_1 = [\"Il fait beau\"]\n",
    "response_2 = [\"Il est beau\"]\n",
    "response_3 = [\"Il va faire beau\"]\n",
    "response_4 = [\"Il a fait beau\"]\n",
    "response_5 = [\"C'est tr√®s beau\"]\n",
    "\n",
    "# Extraire les embeddings\n",
    "question_embedding = extract_features(question)\n",
    "responses_embeddings = extract_features(responses)\n",
    "response_1_embedding = extract_features(response_1)\n",
    "response_2_embedding = extract_features(response_2)\n",
    "response_3_embedding = extract_features(response_3)\n",
    "response_4_embedding = extract_features(response_4)\n",
    "response_5_embedding = extract_features(response_5)\n",
    "\n",
    "# Calculer la similarit√© cosinus entre la question et les r√©ponses\n",
    "cos_similarities = cosine_similarity(question_embedding, responses_embeddings)\n",
    "\n",
    "# Exemple de valeur moyenne de la similarit√© cosinus (pour une paire)\n",
    "mean_cos_similarity = np.mean(cos_similarities)\n",
    "\n",
    "cos_similaritie_1 = cosine_similarity(question_embedding, response_1_embedding)\n",
    "cos_similaritie_2 = cosine_similarity(question_embedding, response_2_embedding)\n",
    "cos_similaritie_3 = cosine_similarity(question_embedding, response_3_embedding)\n",
    "cos_similaritie_4 = cosine_similarity(question_embedding, response_4_embedding)\n",
    "cos_similaritie_5 = cosine_similarity(question_embedding, response_5_embedding)\n",
    "\n",
    "# Enregistrer le mod√®le dans MLflow\n",
    "mlflow.set_experiment(\"Solon-embeddings\")\n",
    "\n",
    "with mlflow.start_run() as run:\n",
    "    # Enregistrer le mod√®le PyTorch\n",
    "    mlflow.pytorch.log_model(model, \"solon-embeddings-large-model\")\n",
    "    # Enregistrer le tokenizer comme artefact\n",
    "    tokenizer.save_pretrained(\"models/solon-embeddings-large-tokenizer\")\n",
    "    \n",
    "    # Enregistrer les param√®tres et les m√©triques\n",
    "    mlflow.log_param(\"model_name\", \"OrdalieTech/Solon-embeddings-large-0.1\")\n",
    "    mlflow.log_param(\"source\", \"Script d'installation Solon-embeddings-large-0.1.ipynb\")\n",
    "    mlflow.log_metric(\"mean_cos_similarity\", mean_cos_similarity)\n",
    "    mlflow.log_metric(\"cos_similarity_top_1\", cos_similaritie_1)\n",
    "    mlflow.log_metric(\"cos_similarity_top_2\", cos_similaritie_2)\n",
    "    mlflow.log_metric(\"cos_similarity_top_3\", cos_similaritie_3)\n",
    "    mlflow.log_metric(\"cos_similarity_top_4\", cos_similaritie_4)\n",
    "    mlflow.log_metric(\"cos_similarity_top_5\", cos_similaritie_5)\n",
    "    \n",
    "    # Inf√©rer la signature du mod√®le\n",
    "    signature = infer_signature(question, question_embedding)\n",
    "    \n",
    "    # Loguer le mod√®le avec la signature et g√©rer les versions\n",
    "    mlflow.pytorch.log_model(\n",
    "        pytorch_model=model,\n",
    "        artifact_path=\"solon-embeddings-large-model\",\n",
    "        signature=signature,\n",
    "        registered_model_name=\"pytorch-solon-embeddings-large-model\",\n",
    "        await_registration_for=10  # Temps d'attente pour la cr√©ation de la version (optionnel)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: 6d780e028b664e8cadb6555fcd642692\n"
     ]
    }
   ],
   "source": [
    "# Afficher l'ID de l'ex√©cution pour r√©f√©rence future\n",
    "run_id = run.info.run_id\n",
    "print(f\"Run ID: {run_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_api_anderson",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
